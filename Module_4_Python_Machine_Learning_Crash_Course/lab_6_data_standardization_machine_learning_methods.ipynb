{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f88ca25-01bf-401f-b224-617b27f96ee9",
   "metadata": {},
   "source": [
    "# Machine Learning Methods: Data Standardization\n",
    "\n",
    "### Data standardization is the conversion of data into a standard, uniform format, making it consistent across different data sets and easier to understand for computer systems. It's often performed when pre-processing data for input into machine learning or statistical models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e88012-3de4-45d2-9bc4-8e415cc0fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938bff2-2d57-4585-9337-ffc0ed1af7f0",
   "metadata": {},
   "source": [
    "## Lets create some synthetic data to help us understand Data Standardization better!\n",
    "## We will also be using a new tool for data standardization called StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28848519-37f2-4e2c-8f84-e9d5340206ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First lets import our new tool!\n",
    "## There are a few different types of Scalars but for this lesson we will be using Standard Scaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54284ee9-80ec-48c5-97ea-acfbc06fed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets create some syntthetic data!\n",
    "\n",
    "X = 100*np.random.rand(200,4)+55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e418cc-31de-4f15-badb-eb6f786f96fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([107.03910567, 104.11781393, 106.01212783, 104.58907429])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now lets see the mean of those new synthetic data! \n",
    "## The mean is import for using a Scaler\n",
    "\n",
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9117ab1-b0d4-4237-a844-de4eb40328b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.30753689, 28.78521087, 28.94033065, 29.17456443])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now lets see the std of those new synthetic data! \n",
    "## The std is import for using a Scaler\n",
    "\n",
    "X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b008c25a-fd36-41e6-8622-907d6618c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now lets use StandardScaler and create a new scaled variable\n",
    "\n",
    "s = StandardScaler()\n",
    "x_scaled = s.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f1e1bcc-444c-46e2-a26e-0c675bb4bcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.01660952e-16, -7.14983628e-16, -9.17044218e-16,  3.90798505e-16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now that we have applied our scaler lets check the mean and std again for x_scaled\n",
    "## Notice how we have scaled the mean down into a range near 0 and the std to near 1 \n",
    "## almost as if its a boolean statement. We use the scaler to standardize our larger variable data down into near boolean values\n",
    "\n",
    "x_scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c6e561-d4fc-4c1c-b695-7a40fbfff875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6a0827-794b-4655-963f-77c7b294841a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efc4bc-a04a-4184-a412-a6e9e02d5c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae1a32-a2b1-4984-8e6b-fb08f1729ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1950dbef-05f9-42f9-8e69-a063cfa96d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e8d78-4335-47b6-ad7d-8aa17773631e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a3436-8f7f-4125-81b6-de56be961718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
